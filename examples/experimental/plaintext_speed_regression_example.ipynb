{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Ordinary least squared regression and LDLt decomposition](#OLSandLDLt)\n",
    "* [LDLt decomposition, forward/back-solving](#LDLt)\n",
    "* [Secure linear regression example](#OLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch as th\n",
    "import syft as sy\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up Sandbox...\n",
      "\t- Hooking PyTorch\n",
      "\t- Creating Virtual Workers:\n",
      "\t\t- bob\n",
      "\t\t- theo\n",
      "\t\t- jason\n",
      "\t\t- alice\n",
      "\t\t- andy\n",
      "\t\t- jon\n",
      "\tStoring hook and workers as global variables...\n",
      "\tLoading datasets from SciKit Learn...\n",
      "\t\t- Boston Housing Dataset\n",
      "\t\t- Diabetes Dataset\n",
      "\t\t- Breast Cancer Dataset\n",
      "\t- Digits Dataset\n",
      "\t\t- Iris Dataset\n",
      "\t\t- Wine Dataset\n",
      "\t\t- Linnerud Dataset\n",
      "\tDistributing Datasets Amongst Workers...\n",
      "\tCollecting workers into a VirtualGrid...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "sy.create_sandbox(globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='OLSandLDLt'>Ordinary least squared regression and LDLt decomposition</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='LDLt'>LDLt decomposition, forward/back-solving</a>\n",
    "\n",
    "These are torch implementations of basic linear algebra routines we'll be leveraging to perform regression (as also in parts of the next section). \n",
    "- Forward/back-solving allows us to solve linear systems efficiently and stably for triangular systems of equations.\n",
    "- LDLt decomposition lets us reduce any linear system to two triangular ones. It performs a role similar to Cholesky decomposition (normally available as method of a torch tensor), but does not require computing square roots. This makes makes LDLt more amenable to the secure setting.\n",
    "\n",
    "**NOTE**: The main obstruction to implementing this functionality for `AdditiveSharingTensor` is that `AdditiveSharingTensor` does not expose the same interface for indexing as python tensors do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _eye(n):\n",
    "    \"\"\"th.eye doesn't seem to work after hooking torch, so just adding\n",
    "    a workaround for now.\n",
    "    \"\"\"\n",
    "    return th.FloatTensor(np.eye(n))\n",
    "\n",
    "\n",
    "def ldlt_decomposition(x):\n",
    "    \"\"\"Decompose the square, symmetric, full-rank matrix X as X = LDL^t, where \n",
    "        - L is upper triangular\n",
    "        - D is diagonal.\n",
    "    X must be a square, symmetric matrix of full rank.\n",
    "    \"\"\"\n",
    "    n, _ = x.shape\n",
    "    l, diag = _eye(n), th.zeros(n).float()\n",
    "\n",
    "    for j in range(n):\n",
    "        diag[j] = x[j, j] - (th.sum((l[j, :j] ** 2) * diag[:j]))\n",
    "        for i in range(j + 1, n):\n",
    "            # instability is a concern for small d.\n",
    "            l[i, j] = (x[i, j] - th.sum(diag[:j] * l[i, :j] * l[j, :j])) / diag[j]\n",
    "\n",
    "    return l, th.diag(diag), l.transpose(0, 1)\n",
    "\n",
    "\n",
    "def back_solve(u, y):\n",
    "    \"\"\"Solve Ux = y for U a square, upper triangular matrix\"\"\"\n",
    "    n = u.shape[0]\n",
    "    x = th.zeros(n)\n",
    "    for i in range(n - 1, -1, -1):\n",
    "        x[i] = (y[i] - th.sum(u[i, i+1:] * x[i+1:])) / u[i, i]\n",
    "\n",
    "    return x.reshape(-1, 1)\n",
    "\n",
    "\n",
    "def forward_solve(l, y):\n",
    "    \"\"\"Solve Lx = y for L a square, lower triangular matrix of full rank.\"\"\"\n",
    "    n = l.shape[0]\n",
    "    x = th.zeros(n)\n",
    "    for i in range(0, n):\n",
    "        x[i] = (y[i] - th.sum(l[i, :i] * x[:i])) / l[i, i]\n",
    "\n",
    "    return x.reshape(-1, 1)\n",
    "\n",
    "\n",
    "def invert_triangular(t, upper=True):\n",
    "    \"\"\"\n",
    "    Invert by repeated forward/back-solving.\n",
    "    TODO: -Could be made more efficient with vectorized implementation of forward/backsolve\n",
    "          -detection and validation around triangularity/squareness\n",
    "    \"\"\"\n",
    "    solve = back_solve if upper else forward_solve\n",
    "    t_inv = th.zeros_like(t)\n",
    "    n = t.shape[0]\n",
    "    for i in range(n):\n",
    "        e = th.zeros(n, 1)\n",
    "        e[i] = 1.\n",
    "        t_inv[:, [i]] = solve(t, e)\n",
    "    return t_inv\n",
    "\n",
    "\n",
    "def solve_symmetric(a, y):\n",
    "    \"\"\"Solve the linear system Ax = y where A is a symmetric matrix of full rank.\"\"\"\n",
    "    l, d, lt = ldlt_decomposition(a)\n",
    "    \n",
    "    # TODO: more efficient to just extract diagonal of d as 1D vector and scale?h\n",
    "    x_ = forward_solve(l.mm(d), y)\n",
    "    return back_solve(lt, x_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='OLS'>Secure linear regression example</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem\n",
    "We're solving \n",
    "$$ \\min_\\beta \\|X \\beta - y\\|_2 $$\n",
    "in the situation where the data $(X, y)$ is horizontally partitioned. That is, each worker $w$ owns chunks $X_w, y_w$ of the rows of $X$ and $y$.\n",
    "\n",
    "#### Goals\n",
    "We want to do this \n",
    "* securely \n",
    "* without network bandwith that scales with the number of rows of $X$. \n",
    "\n",
    "#### Plan\n",
    "\n",
    "1. (**local compression**): each worker locally computes $X_w^t X_w$ and $X_w^t y_w$ in plain text.\n",
    "2. (**secure summing**): securely compute the sums $$\\begin{align}X^t X &= \\sum_w X^t_w X_w \\\\ X^t y &= \\sum_w X^t_w y_w \\end{align}$$ as an AdditiveSharingTensor. Some worker or other party (here the local worker) will have a pointers to those two AdditiveSharingTensors.\n",
    "3. (**secure solve**): We can then solve $X^tX\\beta = X^ty$ for $\\beta$ by a sequence of operations on that pointer (specifically, we apply `solve_symmetric` defined above).\n",
    "\n",
    "#### Example data: \n",
    "The correct $\\beta$ is $[1, 2, -1]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = th.tensor(10 * np.random.randn(30000, 3))\n",
    "y = (X[:, 0] + 2 * X[:, 1] - X[:, 2]).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into chunks and send a chunk to each worker, storing pointers to chunks in two `MultiPointerTensor`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "workers = [alice, bob, theo]\n",
    "crypto_provider = jon\n",
    "chunk_size = int(X.shape[0] / len(workers))\n",
    "\n",
    "def _get_chunk_pointers(data, chunk_size, workers):\n",
    "    return [\n",
    "        data[(i * chunk_size):((i+1)*chunk_size), :].send(worker)\n",
    "        for i, worker in enumerate(workers)\n",
    "    ] \n",
    "\n",
    "X_ptrs = sy.MultiPointerTensor(\n",
    "    children=_get_chunk_pointers(X, chunk_size, workers))\n",
    "y_ptrs = sy.MultiPointerTensor(\n",
    "    children=_get_chunk_pointers(y, chunk_size, workers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### local compression\n",
    "This is the only step that depends on the number of rows of $X, y$, and it's performed locally on each worker in plain text. The result is two `MultiPointerTensor`s with pointers to each workers' summand of $X^tX$ (or $X^ty$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt_ptrs = X_ptrs.transpose(0, 1)\n",
    "\n",
    "XtX_summand_ptrs = Xt_ptrs.mm(X_ptrs)\n",
    "Xty_summand_ptrs = Xt_ptrs.mm(y_ptrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### secure sum\n",
    "We add those summands up in two steps:\n",
    "- share each summand among all other workers\n",
    "- move the resulting pointers to one place (here just the local worker) and add 'em up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generate_shared_summand_pointers(\n",
    "        summand_ptrs, \n",
    "        workers, \n",
    "        crypto_provider):\n",
    "\n",
    "    for worker_id, summand_pointer in summand_ptrs.child.items():\n",
    "        shared_summand_pointer = summand_pointer.fix_precision().share(\n",
    "            *workers, crypto_provider=crypto_provider)\n",
    "        yield shared_summand_pointer.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "XtX_shared = sum(\n",
    "    _generate_shared_summand_pointers(\n",
    "        XtX_summand_ptrs, workers, crypto_provider))\n",
    "\n",
    "Xty_shared = sum(_generate_shared_summand_pointers(\n",
    "    Xty_summand_ptrs, workers, crypto_provider))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### secure solve\n",
    "The coefficient $\\beta$ is the solution to\n",
    "$$X^t X \\beta = X^t y$$\n",
    "\n",
    "We solve for $\\beta$ by \n",
    "1. Decomposing $X^t X = LDL^t$, where L is a lower triangular matrix and $D$ is a diagonal matrix (for more details, see https://en.wikipedia.org/wiki/Cholesky_decomposition#LDL_decomposition). \n",
    "2. Solving $L \\alpha = X^ty$, for $\\alpha$ which is straightforward since $L$ is lower-triangular.\n",
    "3. Solving $D L^t \\beta = \\alpha$, for $\\beta$, which is also straightforward since $D L^t$ is upper-triangular.\n",
    "\n",
    "Critically, all steps are just compositions of linear operations that are supported by `AdditiveSharingTensor`. In particular, unlike the classic Cholesky decomposition, the $LDL^t$ decomposition in step 1 does not involve taking square roots, which would be challenging in the secure setting.\n",
    "\n",
    "We implement these steps below. \n",
    "\n",
    "**TODO**: At the moment, `AdditiveSharingTensor` doesn't appear to support the types of indexing operations used. Seems like it should be possible to modify its `__getitem__` method to support these, but having trouble figuring out how this interacts with the hooking that's going on. Instead, will just perform the computation on the local worker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = solve_symmetric(XtX_shared.get().float_precision(), Xty_shared.get().float_precision())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000],\n",
       "        [ 2.0000],\n",
       "        [-1.0000]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DASH and QR-decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The QR decomposition\n",
    "\n",
    "Every $m \\times n$ real matrix $A$ with $m \\geq n$ can be written as $$A = QR$$ for $Q$ orthogonal and $R$ upper triangular. This is helpful in solving systems of equations and is one strategy for eigenvalue problems. It is also central to the compression idea of [DASH](https://arxiv.org/pdf/1901.09531.pdf). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Full QR decomposition via Householder transforms, \n",
    "following Numerical Linear Algebra (Trefethen and Bau).\n",
    "\"\"\"\n",
    "\n",
    "def _apply_householder_transform(a, v):\n",
    "    return a - 2 * v.mm(v.transpose(0, 1).mm(a))\n",
    "\n",
    "\n",
    "def _build_householder_matrix(v):\n",
    "    n = v.shape[0]\n",
    "    u = v / v.norm()\n",
    "    return _eye(n) - 2 * u.mm(u.transpose(0, 1))\n",
    "\n",
    "\n",
    "def _householder_qr_step(a):\n",
    "\n",
    "    x = a[:, 0].reshape(-1, 1)\n",
    "    alpha = x.norm()\n",
    "    u = x.copy()\n",
    "\n",
    "    # note: can get better stability by multiplying by sign(u[0, 0])\n",
    "    # (where sign(0) = 1); is this supported in the secure context?\n",
    "    u[0, 0] += u.norm()\n",
    "    \n",
    "    # is there a simple way of getting around computing the norm twice?\n",
    "    u /= u.norm()\n",
    "    a = _apply_householder_transform(a, u)\n",
    "\n",
    "    return a, u\n",
    "\n",
    "\n",
    "def _recover_q(householder_vectors):\n",
    "    \"\"\"\n",
    "    Build the matrix Q from the Householder transforms.\n",
    "    \"\"\"\n",
    "    n = len(householder_vectors)\n",
    "\n",
    "    def _apply_transforms(x):\n",
    "        \"\"\"Trefethen and Bau, Algorithm 10.3\"\"\"\n",
    "        for k in range(n-1, -1, -1):\n",
    "            x[k:, :] = _apply_householder_transform(\n",
    "                x[k:, :], \n",
    "                householder_vectors[k])\n",
    "        return x\n",
    "\n",
    "    m = householder_vectors[0].shape[0]\n",
    "    n = len(householder_vectors)\n",
    "    q = th.zeros(m, m)\n",
    "    \n",
    "    # Determine q by evaluating it on a basis\n",
    "    for i in range(m):\n",
    "        e = th.zeros(m, 1)\n",
    "        e[i] = 1.\n",
    "        q[:, [i]] = _apply_transforms(e)\n",
    "    \n",
    "    return q\n",
    "\n",
    "\n",
    "def qr(a, return_q=True):\n",
    "    \"\"\"\n",
    "    :param a: shape (m, n), m >= n\n",
    "    :return: - orthogonal q of shape (m, m), \n",
    "             - upper-triangular of shape (m, n)\n",
    "    \"\"\"\n",
    "    m, n = a.shape\n",
    "    assert m >= n, \\\n",
    "        f\"Passed a of shape {a.shape}, must have a.shape[0] >= a.shape[1]\"\n",
    "\n",
    "    r = a.copy()\n",
    "    householder_unit_normal_vectors = []\n",
    "\n",
    "    for k in range(n):\n",
    "        r[k:, k:], u = _householder_qr_step(r[k:, k:])\n",
    "        householder_unit_normal_vectors.append(u)\n",
    "    if return_q:\n",
    "        q = _recover_q(householder_unit_normal_vectors)\n",
    "    else:\n",
    "        q = None\n",
    "    return q, r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PASSED for \n",
      "tensor([[1., 0., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [0., 1., 1.]])\n",
      "\n",
      "PASSED for \n",
      "tensor([[1., 0., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Basic tests for QR decomposition\n",
    "\"\"\"\n",
    "\n",
    "def _assert_small(x, failure_msg, threshold=1E-5):\n",
    "    norm = x.norm()\n",
    "    assert norm < threshold, failure_msg\n",
    "\n",
    "\n",
    "def _test_case(a): \n",
    "    \n",
    "    q, r = qr(a)\n",
    "    \n",
    "    # actually have QR = A\n",
    "    _assert_small(q.mm(r) - a, \"QR = A failed\")\n",
    "\n",
    "    # Q is orthogonal\n",
    "    m, _ = a.shape\n",
    "    _assert_small(\n",
    "        q.mm(q.transpose(0, 1)) - _eye(m),\n",
    "        \"QQ^t = I failed\"\n",
    "    )\n",
    "    \n",
    "    # R is upper triangular\n",
    "    lower_triangular_entries = th.tensor([\n",
    "        r[i, j].item() for i in range(r.shape[0]) \n",
    "             for j in range(i)])\n",
    "\n",
    "    _assert_small(\n",
    "        lower_triangular_entries,\n",
    "        \"R is not upper triangular\"\n",
    "    )\n",
    "\n",
    "    print(f\"PASSED for \\n{a}\\n\")\n",
    "\n",
    "\n",
    "def test_qr():\n",
    "    _test_case(\n",
    "        th.tensor([[1, 0, 1],\n",
    "                   [1, 1, 0],\n",
    "                   [0, 1, 1]]).float()\n",
    "    )\n",
    "\n",
    "    _test_case(\n",
    "        th.tensor([[1, 0, 1],\n",
    "                   [1, 1, 0],\n",
    "                   [0, 1, 1],\n",
    "                   [1, 1, 1],]).float()\n",
    "    )\n",
    "    \n",
    "test_qr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DASH implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples_by_player = {\n",
    "    'alice': 1000,\n",
    "    'bob': 2000,\n",
    "    'carla': 1500\n",
    "}\n",
    "\n",
    "m = 10000\n",
    "k = 3\n",
    "d = sum(n_samples_by_player.values()) - k - 1\n",
    "\n",
    "\n",
    "def _generate_player_data(n, m, k):\n",
    "    y = th.randn(n, 1)\n",
    "    X = th.randn(n, m)\n",
    "    C = th.randn(n, k)\n",
    "    _, R = qr(C, return_q=False)\n",
    "    return y, X, C, R\n",
    "\n",
    "\n",
    "def _dot(X):\n",
    "    return (X * X).sum(dim=0).reshape(-1, 1)\n",
    "\n",
    "\n",
    "def dash_example(player_data, m, k):\n",
    "\n",
    "    player_data = {\n",
    "        p: _generate_player_data(n, m, k)\n",
    "        for p, n in n_samples_by_player.items()\n",
    "    }\n",
    "\n",
    "    _, R = qr(th.cat([R[:k, :] for _, (_, _, _, R) in player_data.items()], dim=0))\n",
    "    invR = invert_triangular(R[:k, :])\n",
    "\n",
    "    Qs, Qtys, QtXs, yys, Xys, XXs = {}, {}, {}, {}, {}, {}\n",
    "\n",
    "    for p, (y, X, C, _) in player_data.items():\n",
    "        Qs[p] = C.mm(invR)\n",
    "        Qtys[p] = Qs[p].transpose(0, 1).mm(y)\n",
    "        QtXs[p] = Qs[p].transpose(0, 1).mm(X)\n",
    "        \n",
    "        yys[p] = y.norm()\n",
    "        Xys[p] = X.transpose(0, 1).mm(y)\n",
    "        XXs[p] = _dot(X)\n",
    "    \n",
    "    yy = sum(yys.values())\n",
    "    Xy = sum(Xys.values())\n",
    "    XX = sum(XXs.values())\n",
    "    \n",
    "    Qty = sum(Qtys.values())\n",
    "    Qty = sum(Qtys.values())\n",
    "    QtX = sum(QtXs.values())\n",
    "    \n",
    "    QtyQty = _dot(Qty)\n",
    "    QtXQty = QtX.transpose(0, 1).mm(Qty)\n",
    "    QtXQtX = _dot(QtX)\n",
    "    \n",
    "    yyq = yy - QtyQty\n",
    "    Xyq = Xy - QtXQty\n",
    "    XXq = XX - QtXQtX\n",
    "    \n",
    "    beta = Xyq / XXq\n",
    "    sigma = (yyq / XXq - (beta ** 2))\n",
    "    tstat = beta / sigma\n",
    "    pval = 2 * stats.t.cdf(-abs(tstat), d)\n",
    "    return beta, sigma, tstat, pval\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 1])\n",
      "torch.Size([10000, 1])\n",
      "torch.Size([10000, 1])\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "results = dash_example(n_samples_by_player, m, k)\n",
    "for r in results:\n",
    "    print(r.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "workers = [alice, bob, theo]\n",
    "\n",
    "n_samples_by_worker = {\n",
    "    alice.id: 1000,\n",
    "    bob.id: 2000,\n",
    "    theo.id: 1500\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "m = 10000\n",
    "k = 3\n",
    "d = sum(n_samples_by_player.values()) - k - 1\n",
    "\n",
    "def _generate_player_data_pointers(n, m, k, worker):\n",
    "\n",
    "    y = th.randn(n, 1).send(worker)\n",
    "    X = th.randn(n, m).send(worker)\n",
    "    C = th.randn(n, k).send(worker)\n",
    "\n",
    "    _, R = qr(C, return_q=False)\n",
    "    return y, X, C, R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
