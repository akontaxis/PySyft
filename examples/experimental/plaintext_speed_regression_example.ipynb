{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch as th\n",
    "import syft as sy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up Sandbox...\n",
      "\t- Hooking PyTorch\n",
      "\t- Creating Virtual Workers:\n",
      "\t\t- bob\n",
      "\t\t- theo\n",
      "\t\t- jason\n",
      "\t\t- alice\n",
      "\t\t- andy\n",
      "\t\t- jon\n",
      "\tStoring hook and workers as global variables...\n",
      "\tLoading datasets from SciKit Learn...\n",
      "\t\t- Boston Housing Dataset\n",
      "\t\t- Diabetes Dataset\n",
      "\t\t- Breast Cancer Dataset\n",
      "\t- Digits Dataset\n",
      "\t\t- Iris Dataset\n",
      "\t\t- Wine Dataset\n",
      "\t\t- Linnerud Dataset\n",
      "\tDistributing Datasets Amongst Workers...\n",
      "\tCollecting workers into a VirtualGrid...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "sy.create_sandbox(globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ordinary least squared regression and LDLt decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example data**: the correct $\\beta$ is $[1, 2, -1]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = th.tensor(10 * np.random.randn(30, 3))\n",
    "y = (X[:, 0] + 2 * X[:, 1] - X[:, 2]).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into chunks and send a chunk to each worker, storing pointers to chunks in two `MultiPointerTensor`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "workers = [alice, bob, theo]\n",
    "crypto_provider = jon\n",
    "chunk_size = int(X.shape[0] / len(workers))\n",
    "\n",
    "def _get_chunk_pointers(data, chunk_size, workers):\n",
    "    return [\n",
    "        data[(i * chunk_size):((i+1)*chunk_size), :].send(worker)\n",
    "        for i, worker in enumerate(workers)\n",
    "    ] \n",
    "\n",
    "X_ptrs = sy.MultiPointerTensor(\n",
    "    children=_get_chunk_pointers(X, chunk_size, workers))\n",
    "y_ptrs = sy.MultiPointerTensor(\n",
    "    children=_get_chunk_pointers(y, chunk_size, workers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the \"big data\" step, and it's performed locally on each worker in plain text. The result is two `MultiPointerTensor`s with pointers to each workers' summand of $X^tX$ (or $X^ty$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt_ptrs = X_ptrs.transpose(0, 1)\n",
    "\n",
    "XtX_summand_ptrs = Xt_ptrs.mm(X_ptrs)\n",
    "Xty_summand_ptrs = Xt_ptrs.mm(y_ptrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add those summands up in two steps:\n",
    "- share each summand among all other workers\n",
    "- move the resulting pointers to one place (here just the local worker) and add 'em up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generate_shared_summand_pointers(\n",
    "        summand_ptrs, \n",
    "        workers, \n",
    "        crypto_provider):\n",
    "\n",
    "    for worker_id, summand_pointer in summand_ptrs.child.items():\n",
    "        shared_summand_pointer = summand_pointer.fix_precision().share(\n",
    "            *workers, crypto_provider=crypto_provider)\n",
    "        yield shared_summand_pointer.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "XtX_shared = sum(\n",
    "    _generate_shared_summand_pointers(\n",
    "        XtX_summand_ptrs, workers, crypto_provider))\n",
    "\n",
    "Xty_shared = sum(_generate_shared_summand_pointers(\n",
    "    Xty_summand_ptrs, workers, crypto_provider))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coefficient $\\beta$ is the solution to\n",
    "$$X^t X \\beta = X^t y$$\n",
    "\n",
    "We solve for $\\beta$ by \n",
    "1. Decomposing $X^t X = LDL^t$, where L is a lower triangular matrix and $D$ is a diagonal matrix (for more details, see https://en.wikipedia.org/wiki/Cholesky_decomposition#LDL_decomposition). \n",
    "2. Solving $L \\alpha = X^ty$, for $\\alpha$ which is straightforward since $L$ is lower-triangular.\n",
    "3. Solving $D L^t \\beta = \\alpha$, for $\\beta$, which is also straightforward since $D L^t$ is upper-triangular.\n",
    "\n",
    "Critically, all steps are just compositions of linear operations that are supported by `AdditiveSharingTensor`. In particular, unlike the classic Cholesky decomposition, the $LDL^t$ decomposition in step 1 does not involve taking square roots, which would be challenging in the secure setting.\n",
    "\n",
    "We implement these steps below. \n",
    "\n",
    "**TODO**: At the moment, `AdditiveSharingTensor` doesn't appear to support the types of indexing operations used. Seems like it should be possible to modify its `__getitem__` method to support these, but having trouble figuring out how this interacts with the hooking that's going on. Instead, will just perform the computation on the local worker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _eye(n):\n",
    "    \"\"\"th.eye doesn't seem to work after hooking torch, so just adding\n",
    "    a workaround for now.\n",
    "    \"\"\"\n",
    "    return th.FloatTensor(np.eye(n))\n",
    "\n",
    "\n",
    "def ldlt_decomposition(x):\n",
    "    \"\"\"Decompose the square, symmetric, full-rank matrix X as X = LDL^t, where \n",
    "        - L is upper triangular\n",
    "        - D is diagonal.\n",
    "    X must be a square, symmetric matrix of full rank.\n",
    "    \"\"\"\n",
    "    n, _ = x.shape\n",
    "    l, diag = _eye(n), th.zeros(n).float()\n",
    "\n",
    "    for j in range(n):\n",
    "        diag[j] = x[j, j] - (th.sum((l[j, :j] ** 2) * diag[:j]))\n",
    "        for i in range(j + 1, n):\n",
    "            # instability is a concern for small d.\n",
    "            l[i, j] = (x[i, j] - th.sum(diag[:j] * l[i, :j] * l[j, :j])) / diag[j]\n",
    "\n",
    "    return l, th.diag(diag), l.transpose(0, 1)\n",
    "\n",
    "\n",
    "def solve_upper_triangular(u, y):\n",
    "    \"\"\"Solve Ux = y for U a square, upper triangular matrix\"\"\"\n",
    "    n = u.shape[0]\n",
    "    x = th.zeros(n)\n",
    "    for i in range(n - 1, -1, -1):\n",
    "        x[i] = (y[i] - th.sum(u[i, i+1:] * x[i+1:])) / u[i, i]\n",
    "\n",
    "    return x.reshape(-1, 1)\n",
    "\n",
    "\n",
    "def solve_lower_triangular(l, y):\n",
    "    \"\"\"Solve Lx = y for L a square, lower triangular matrix of full rank.\"\"\"\n",
    "    n = l.shape[0]\n",
    "    x = th.zeros(n)\n",
    "    for i in range(0, n):\n",
    "        x[i] = (y[i] - th.sum(l[i, :i] * x[:i])) / l[i, i]\n",
    "\n",
    "    return x.reshape(-1, 1)\n",
    "\n",
    "\n",
    "def solve_symmetric(a, y):\n",
    "    \"\"\"Solve the linear system Ax = y where A is a symmetric matrix of full rank.\"\"\"\n",
    "    l, d, lt = ldlt_decomposition(a)\n",
    "    x_ = solve_lower_triangular(l.mm(d), y)\n",
    "    return solve_upper_triangular(lt, x_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = solve_symmetric(XtX_shared.get().float_precision(), Xty_shared.get().float_precision())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000],\n",
       "        [ 2.0000],\n",
       "        [-1.0000]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QR-decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Full QR decomposition via Householder transforms, \n",
    "following the implementationof Numerical Linear Algebra \n",
    "(Trefethen and Bau).\n",
    "\"\"\"\n",
    "\n",
    "def _apply_householder_transform(a, v):\n",
    "    return a - 2 * v.mm(v.transpose(0, 1).mm(a))\n",
    "\n",
    "\n",
    "def _build_householder_matrix(v):\n",
    "    n = v.shape[0]\n",
    "    u = v / v.norm()\n",
    "    return _eye(n) - 2 * u.mm(u.transpose(0, 1))\n",
    "\n",
    "\n",
    "def _householder_qr_step(a):\n",
    "\n",
    "    x = a[:, 0].reshape(-1, 1)\n",
    "    alpha = x.norm()\n",
    "    u = x.copy()\n",
    "\n",
    "    # note: can get better stability by multiplying by sign(u[0, 0])\n",
    "    # (where sign(0)n = 1); is this supported in the secure context?\n",
    "    u[0, 0] += u.norm()\n",
    "    \n",
    "    # is there a simple way of getting around computing the norm twice?\n",
    "    u /= u.norm()\n",
    "    a = _apply_householder_transform(a, u)\n",
    "\n",
    "    return a, u\n",
    "\n",
    "\n",
    "def _recover_q(householder_vectors):\n",
    "    \"\"\"\n",
    "    Build the matrix Q from the Householder transforms.\n",
    "    \"\"\"\n",
    "    n = len(householder_vectors)\n",
    "\n",
    "    def _apply_transforms(x):\n",
    "        \"\"\"Trefethen and Bau, Algorithm 10.3\"\"\"\n",
    "        for k in range(n-1, -1, -1):\n",
    "            x[k:, :] = _apply_householder_transform(\n",
    "                x[k:, :], \n",
    "                householder_vectors[k])\n",
    "        return x\n",
    "\n",
    "    m = householder_vectors[0].shape[0]\n",
    "    n = len(householder_vectors)\n",
    "    q = th.zeros(m, m)\n",
    "    \n",
    "    # Determine q by evaluating it on a basis\n",
    "    for i in range(m):\n",
    "        e = th.zeros(m, 1)\n",
    "        e[i] = 1.\n",
    "        q[:, [i]] = _apply_transforms(e)\n",
    "    \n",
    "    return q\n",
    "\n",
    "\n",
    "def qr(a, return_q=True):\n",
    "    \"\"\"\n",
    "    :param a: shape (m, n), m >= n\n",
    "    :return: - orthogonal q of shape (m, m), \n",
    "             - upper-triangular of shape (m, n)\n",
    "    \"\"\"\n",
    "    m, n = a.shape\n",
    "    assert m >= n, \\\n",
    "        f\"Passed a of shape {a.shape}, must have a.shape[0] >= a.shape[1]\"\n",
    "\n",
    "    r = a.copy()\n",
    "    householder_unit_normal_vectors = []\n",
    "\n",
    "    for k in range(n):\n",
    "        r[k:, k:], u = _householder_qr_step(r[k:, k:])\n",
    "        householder_unit_normal_vectors.append(u)\n",
    "    if return_q:\n",
    "        q = _recover_q(householder_unit_normal_vectors)\n",
    "    else:\n",
    "        q = None\n",
    "    return q, r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PASSED for \n",
      "tensor([[1., 0., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [0., 1., 1.]])\n",
      "\n",
      "PASSED for \n",
      "tensor([[1., 0., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Basic tests for QR decomposition\n",
    "\"\"\"\n",
    "\n",
    "def _assert_small(x, failure_msg, threshold=1E-5):\n",
    "    norm = x.norm()\n",
    "    assert norm < threshold, failure_msg\n",
    "\n",
    "\n",
    "def _test_case(a): \n",
    "    \n",
    "    # decomposition holds\n",
    "    q, r = qr(a)\n",
    "    _assert_small(q.mm(r) - a, \"QR = A failed\")\n",
    "\n",
    "    # q is orthogonal\n",
    "    m, _ = a.shape\n",
    "    _assert_small(\n",
    "        q.mm(q.transpose(0, 1)) - _eye(m),\n",
    "        \"QQ^t = I failed\"\n",
    "    )\n",
    "\n",
    "    _assert_small(\n",
    "        q.transpose(0, 1).mm(q) - _eye(m),\n",
    "        \"QQ^t = I failed\"\n",
    "    )\n",
    "    \n",
    "    # r is upper triangular\n",
    "    lower_triangular_entries = th.tensor([\n",
    "        r[i, j].item() for i in range(r.shape[0]) \n",
    "             for j in range(i)])\n",
    "\n",
    "    _assert_small(\n",
    "        lower_triangular_entries,\n",
    "        \"R is not upper triangular\"\n",
    "    )\n",
    "    print(f\"PASSED for \\n{a}\\n\")\n",
    "\n",
    "\n",
    "_test_case(\n",
    "    th.tensor([[1, 0, 1],\n",
    "               [1, 1, 0],\n",
    "               [0, 1, 1]]).float()\n",
    ")\n",
    "\n",
    "_test_case(\n",
    "    th.tensor([[1, 0, 1],\n",
    "               [1, 1, 0],\n",
    "               [0, 1, 1],\n",
    "               [1, 1, 1],]).float()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DASH implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = 1000\n",
    "n2 = 2000\n",
    "n3 = 1500\n",
    "m = 10000\n",
    "k = 3\n",
    "\n",
    "d = n1 + n2 + n3 - k - 1\n",
    "\n",
    "\n",
    "# Alice\n",
    "y1 = th.randn(n1, 1)\n",
    "X1 = th.randn(n1, m)\n",
    "C1 = th.randn(n1, k)\n",
    "_, R1 = qr(C1)\n",
    "\n",
    "\n",
    "# Bob\n",
    "y2 = th.randn(n2, 1)\n",
    "X2 = th.randn(n2, m)\n",
    "C2 = th.randn(n2, k)\n",
    "_, R2 = qr(C2)\n",
    "\n",
    "\n",
    "# Carla\n",
    "y3 = th.randn(n3, 1)\n",
    "X3 = th.randn(n3, m)\n",
    "C3 = th.randn(n3, k)\n",
    "_, R3 = qr(C3)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.1591e+01,  1.6858e+00,  6.5854e-01],\n",
       "        [ 2.9802e-08, -3.2810e+01,  1.1307e+00],\n",
       "        [ 9.3132e-10, -3.5763e-07, -3.2311e+01],\n",
       "        ...,\n",
       "        [-7.4506e-09, -4.7684e-07,  3.7253e-09],\n",
       "        [-1.1921e-07,  7.1526e-07, -5.9605e-08],\n",
       "        [-5.9605e-08, -1.7881e-07,  1.1921e-07]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
